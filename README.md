# Part 1 Metabarcoding Detective

#### Here are your sequences generated by metabarcoding of environmental DNA from marine water
> \>Seq1_KBH  
> TCTAGCTGGTAACTTAGCCCACGCGGGAGCATCCGTTGATTTAACAATTTTTTCTCTTCATCTAGCAGGTATTTCATCAATTTTAGGCGCTATTAATTTTATTACCACTATTATTAATATAAAACCACCTGCAATTTCACAATATCAAACCCCACTATTTGTTTGAGCCGTATTAATTACAGCCGTCCTTCTTCTCTTATCCCTACCCGTCCTAGCTGCTGGAATTACAATACTTCTGACAGACCGAAACCTAAACACTACCTTTTTTGATCCTGCTGGCGGTGGAGATCCTATTCTTTACCAACATTTGTTC  
> \>Seq2_SO  
> TCTAGCCGGCAATCTTGCCCACGCAGGAGCTTCCGTTGACTTAACTATTTTCTCCCTCCATTTAGCTGGTATTTCCTCAATTTTGGGGGCCATTAATTTTATTACGACCATTATTAACATAAAACCCCCAGCCATCTCCCAATATCAAACTCCACTTTTTGTTTGGGCCGTGTTAGTCACCGCCGTCCTCTTATTACTCTCCCTCCCTGTTTTAGCAGCAGGCATTACTATGCTACTCACAGACCGAAATCTTAATACCACTTTCTTTGACCCGGCAGGCGGAGGGGATCCAATCTTATACCAACACCTCTTT  
> \>Seq3_KBH  
> TTTATCTTCTGTTGAATTTCATAGAGGTCCTGCCGTAGACATTTTAATTACTTCATTACACGCAATTGGTCTTAGTTCATTAGTAGGGGCTATTAATTTTGGGTGTACTAATAAAAACATACCTGTTCCTAAAATGAAAGGGGAAACGTCTGAGCTTTATTTATGAAGGCTAACTGTTACGGCTGTTCTTTTGATTATTTCTGTTCCTGTTTTAGCAGGAGGTATTACTATGCTGTTGTTTGACCGTAACTTTAATAGAACTTTTTTTGACCCTATCGGAGGGGGTGATCCTGTTTTGTTTCAACATTTATTC  
> \>Seq4_SO  
> TCTCGCCGCCGGAATCGCCCATGCTGGGGCCTCTGTCGACTTAGCTATTTTTTCACTTCATCTCGCAGGGATCTCCTCCATTTTAGGGGCCGTAAACTTTATCACCACTACAATTAATATGCGAGCCAGAGGAATAACAATGGACCGAATCCCATTATTTGTTTGGTCCGTTGTAATTACAGCCATCCTATTATTGCTATCTCTCCCGGTATTAGCAGGGGCAATCACTATGTTATTAACCGATCGTAATTTAAACACATCTTTCTTCGACCCGGCAGGGGGTGGAGACCCTATTTTATACCAACACTTATTT  
> \>Seq5_KBH  
> TCTATCCAGGTACCCGTATCACAGAGGGCCAAGAATAGACGTTCTCATTGTGGCCCTTCATTTAG CTGGAGTGAGGTCTTTAGTAGGGGCTATCAATTTTGCCAGTACTAACAAAAACATACCGGCCTTGGAGATAAAAGGGGAGCGAGCTGAGCTCTATGTCTTAAGAATTAGGATCACTGCAGCTCTTCTAATTATTTCTATCCCGGTTCTAGGAGGAGGGATTACAATAATCTTGTTTGACCGGAACTTTAACACGACGTTTTTCGACCCTGCAGGGGGCGGGGATCCTGTTCTGTTTCAACATTTATTT  
> \>Seq6_SO  
> TCTTTCTAGGAATTTGGCCCATTCTAGGGCTGCTTTAGATTGTGCTATTTTTTCTTTACATTTGGCTAGAGTTTCTAGTATTTTAAGGTCTTTAAATTTTATGACCACTTTGTTTAATATGAAAGTAAAAAGGTGGGGGTTGTTTTCTATGTCCTTATTTTGTTGGACAGTGTTAGTCACTACTATTTTATTATTGTTATCTCTTCCTGTTTTAGCTGCAGCTATTACTATGCTGTTGTTTGATCGAAATTTTAATACTTCTTTTTTTGATCCTTCCAGAAGGGGGGACCCTGTCTTGTATCAACATTTGTTT
#### Now you can check the NCBI database using the below BLAST link

https://blast.ncbi.nlm.nih.gov/Blast.cgi

BLAST (Basic Local Alignment Search Tool) is a bioinformatics toolkit that...
- Takes a nucleotide or protein sequence as query and searches large sequence databases for regions of local similarity.  ￼
- Compares the query against database sequences and returns hits ranked by statistical significance of match.  ￼
- Helps infer functional, evolutionary, or homology relationships between the query and known sequences.  ￼
- Supports multiple search types (e.g., nucleotide vs nucleotide, protein vs protein, translated searches).  ￼

You can use these tools interactively on the above USA-hosted website (for now...), but all are avalible as standalone tools to use on servers yourself (e.g. blastn for nucleotide queries).

### Questions to consider for each sequence

- What genetic region do we think this is?  
- Is it from the nuclear genome, mitochondrial, chloroplast or another organelle genome?  
- What is the taxa with the single highest score?  
- Are there any similar hits but for different species?  
- Are there any hits with low coverage (<90%)?  
- Are there multiple genetic variants (haplotypes) for the same species?
#### For each sequence which taxa you think the sequence came from?

### Discussion in plenum 

---

# Part 2 Metabarcoding Bioinformatics

### How do we go from read pairs to a sequence by sample table?

#### First log into the server as normal

Load up the needed libraries so you have them availiable in R. 
```bash
echo '.libPaths(c("/home/ctools/R_libs", .libPaths()))' >> ~/.Rprofile
```
Now make a folder and copy raw files into a directory in which you wnat to work
```bash
cp /home/projects/MTBexercise/*.gz /your/directory/here/
```
Great, now we enter R for the rest of our analysis. A little cheatsheet/reminder on R [here](https://www.rforecology.com/uploads/The_essential_R_Cheatsheet_v1_0.pdf).  
```r
R
```
### 2.1 Setting things up
Let's try and load the libraries
```r
library(dada2)
packageVersion("dada2")
```
Hopefully you see this!
>[1] ‘1.30.0’


Now can we see the copied files in your folder? list.files in r is analagous to ls in bash.
```r
list.files(pattern=".gz")
```
 > "BAR-1_R1_stripped.fastq.gz"  "BAR-1_R2_stripped.fastq.gz"
 > "C1_R1_stripped.fastq.gz"     "C1_R2_stripped.fastq.gz"
 > "C2_R1_stripped.fastq.gz"     "C2_R2_stripped.fastq.gz"
 > "CHAM-1_R1_stripped.fastq.gz" "CHAM-1_R2_stripped.fastq.gz"
 > "RED-1_R1_stripped.fastq.gz"  "RED-1_R2_stripped.fastq.gz"

Make sorted lists of files
```r
fnFs <- sort(list.files(pattern = "_R1_stripped.fastq.gz", full.names = TRUE))
fnRs <- sort(list.files(pattern = "_R2_stripped.fastq.gz", full.names = TRUE))
```

Next we split the name up and assign the names with no suffix to a variable & check them!
```r
sample.names <- sapply(strsplit(basename(fnFs), "_"), "[", 1)
sample.names
```

We then make two plots that show us how many reads we have, what quality they are, and how they change across the NGS read.
```r
pdf("qualityplot.F.pdf",width=8,height=5)
par(mfrow=c(1,2))
plotQualityProfile(fnFs[4:5])
dev.off()

pdf("qualityplot.R.pdf",width=8,height=5)
par(mfrow=c(1,2))
plotQualityProfile(fnRs[4:5])
dev.off()
```
Download these files to your local system. They should look like the below example. 


In gray-scale is a heat map of the frequency of each quality score at each base position. The mean quality score at each position is shown by the green line, and the quartiles of the quality score distribution by the orange lines. The red line shows the scaled proportion of reads that extend to at least that position
You can (hopefully) see that the quality remains above 35 for the entire read across both the forward and reverse read.  

 Now we make a list of files to be filtered and name them
```r
filtFs <- file.path("filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path("filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```
### 2.2 Filtering bad reads
We use the filterAndTrim function to retain a subset of the reads. Look at the [documentation](https://rdrr.io/bioc/dada2/man/filterAndTrim.html) to understand the parameters. 
```r
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs,
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=4)
head(out)
```

### 2.3 Learning errors
dada2 works by calculating an error model unique to each seqeuneced DNA library. It then uses this error model to determine which sequences are real and which are artificts (for e.g. PCR errors or sequencing errors). There is plenty we can do to visualise the error models and refine them, but here we just want to try and go through the pipeline so we assume things are ok and move on. 
```r
path <- "filtered"
filtFs <- sort(list.files(path, pattern="F_filt.fastq.gz", full.names = TRUE))
filtRs <- sort(list.files(path, pattern="R_filt.fastq.gz", full.names = TRUE))

errF <- learnErrors(filtFs, multithread=4)
errR <- learnErrors(filtRs, multithread=4)
```
***Optional*** Look at the [documentation](https://www.rdocumentation.org/packages/dada2/versions/1.0.3/topics/plotErrors) for the plotErrors function if you are interested in interrogating the error profiles. You can generate plots just like you did for the quality plots so give it a go, what can you see?        

### 2.4 Dereplicate and DADA2
Next we dereplicate our samples
```r
derepFs <- derepFastq(list.files("filtered", pattern="F_filt.fastq.gz", full.names = TRUE), verbose=TRUE)
derepRs <- derepFastq(list.files("filtered", pattern="R_filt.fastq.gz", full.names = TRUE), verbose=TRUE)

names(derepFs) <- sapply(strsplit(basename(list.files("filtered", pattern="F_filt.fastq.gz", full.names = TRUE)), "_"), `[`, 1)
names(derepRs) <- sapply(strsplit(basename(list.files("filtered", pattern="R_filt.fastq.gz", full.names = TRUE)), "_"), `[`, 1)
```
...and feed the dereplicated data and our error models into the dada2 alogorithm.
```r
dadaFs <- dada(derepFs, err=errF, multithread=4)
dadaRs <- dada(derepRs, err=errR, multithread=4)
```

### 2.5 Merge and output 
So far all our processing has been on the forward and reverse reads seperately. Now we have some good quality sequences for each direction we can merge them.
```r
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)
head(mergers[[1]])
```
Now we make a sequence table, look at the dimentions and output a csv file for further interrogation.
```r
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
write.csv(t(seqtab),"outputTable.csv")
```
